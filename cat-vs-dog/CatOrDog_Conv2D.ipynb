{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data\n",
    "\n",
    "For this project, I am using the dataset from `Kaggle's` Dog vs Cat competition. I downloaded the zip file extracted it in my project's root directory and extracted the train.zip. Kaggle's train data set contains 25000 images which is difficult to process, hence I have randomly selected 2000 (1000 cats, 1000 dogs) images for training. Also, deleted the test.zip  as I am creating test data set also from their training data set.\n",
    "\n",
    "## Create Folders to hold different data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems like data is already set up. Skipping!\n"
     ]
    }
   ],
   "source": [
    "# create data\n",
    "import os\n",
    "import glob \n",
    "import random \n",
    "import shutil\n",
    "\n",
    "\n",
    "project_path = 'D:\\\\deep-learning\\\\learning-keras\\\\cat-vs-dog'\n",
    "os.chdir(project_path)\n",
    "if os.path.isdir('train/dog') is False:\n",
    "    os.makedirs('train/dog')\n",
    "    os.makedirs('train/cat')\n",
    "    os.makedirs('test/dog')\n",
    "    os.makedirs('test/cat')\n",
    "    os.makedirs('valid/dog')\n",
    "    os.makedirs('valid/cat')\n",
    "    \n",
    "    for c in random.sample(glob.glob('dog*'), 1000):\n",
    "        shutil.move(c, 'train/dog')\n",
    "    for c in random.sample(glob.glob('cat*'), 1000):\n",
    "        shutil.move(c, 'train/cat')\n",
    "    for c in random.sample(glob.glob('dog*'), 200):\n",
    "        shutil.move(c, 'valid/dog')\n",
    "    for c in random.sample(glob.glob('cat*'), 200):\n",
    "        shutil.move(c, 'valid/cat')\n",
    "    for c in random.sample(glob.glob('dog*'), 100):\n",
    "        shutil.move(c, 'test/dog')\n",
    "    for c in random.sample(glob.glob('cat*'), 100):\n",
    "        shutil.move(c, 'test/cat')\n",
    "else:\n",
    "    print('Seems like data is already set up. Skipping!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(project_path)\n",
    "train_path = 'train'\n",
    "test_path = 'test'\n",
    "validation_path = 'valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading images from training dataset\n",
      "Found 2000 images belonging to 2 classes.\n",
      "completed loading images from training dataset\n",
      "loading vlidation images\n",
      "Found 400 images belonging to 2 classes.\n",
      "completed loading validation images\n",
      "loading images from test dataset\n",
      "Found 200 images belonging to 2 classes.\n",
      "completed loading images from test dataset\n"
     ]
    }
   ],
   "source": [
    "image_size = (224, 224)\n",
    "\n",
    "print('loading images from training dataset')\n",
    "train_batches = ImageDataGenerator(preprocessing_function=preprocess_input)\\\n",
    "    .flow_from_directory(batch_size=10, directory=train_path, target_size=image_size, classes=['cat', 'dog'])\n",
    "print('completed loading images from training dataset')\n",
    "\n",
    "print('loading vlidation images')\n",
    "validation_batches = ImageDataGenerator(preprocessing_function=preprocess_input)\\\n",
    "    .flow_from_directory(batch_size=10, directory=validation_path, target_size=image_size, classes=['cat', 'dog'])\n",
    "print('completed loading validation images')\n",
    "\n",
    "print('loading images from test dataset')\n",
    "test_batches = ImageDataGenerator(preprocessing_function=preprocess_input)\\\n",
    "    .flow_from_directory(batch_size=10, directory=test_path, target_size=image_size, classes=['cat', 'dog'], shuffle=False)\n",
    "print('completed loading images from test dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "# padding =  same means we will add 0 paddings to maintain the size of output same as the size of input after convolving  \n",
    "# size is 244 * 244, 3 is for rgb\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 200704)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 401410    \n",
      "=================================================================\n",
      "Total params: 420,802\n",
      "Trainable params: 420,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 200 steps, validate for 40 steps\n",
      "Epoch 1/10\n",
      "200/200 - 84s - loss: 20.6400 - accuracy: 0.5235 - val_loss: 0.6961 - val_accuracy: 0.5475\n",
      "Epoch 2/10\n",
      "200/200 - 73s - loss: 0.6352 - accuracy: 0.6415 - val_loss: 0.7089 - val_accuracy: 0.5750\n",
      "Epoch 3/10\n",
      "200/200 - 74s - loss: 0.5281 - accuracy: 0.7515 - val_loss: 0.7042 - val_accuracy: 0.5850\n",
      "Epoch 4/10\n",
      "200/200 - 74s - loss: 0.4290 - accuracy: 0.8470 - val_loss: 0.9835 - val_accuracy: 0.6000\n",
      "Epoch 5/10\n",
      "200/200 - 78s - loss: 0.1622 - accuracy: 0.9465 - val_loss: 1.1644 - val_accuracy: 0.6075\n",
      "Epoch 6/10\n",
      "200/200 - 73s - loss: 0.1153 - accuracy: 0.9630 - val_loss: 1.2981 - val_accuracy: 0.5700\n",
      "Epoch 7/10\n",
      "200/200 - 73s - loss: 0.1088 - accuracy: 0.9695 - val_loss: 1.6385 - val_accuracy: 0.5975\n",
      "Epoch 8/10\n",
      "200/200 - 74s - loss: 0.1385 - accuracy: 0.9555 - val_loss: 1.4636 - val_accuracy: 0.6075\n",
      "Epoch 9/10\n",
      "200/200 - 83s - loss: 0.0416 - accuracy: 0.9850 - val_loss: 2.0234 - val_accuracy: 0.6000\n",
      "Epoch 10/10\n",
      "200/200 - 74s - loss: 0.0277 - accuracy: 0.9930 - val_loss: 1.9452 - val_accuracy: 0.5975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20a1acd5c88>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we do not pass y here because the generators usually contain y value in them\n",
    "model.fit(x=train_batches, validation_data=validation_batches, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x=test_batches, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true=test_batches.classes, y_pred=rounded_predictions)\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['cat', 'dog'])\n",
    "display = display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
